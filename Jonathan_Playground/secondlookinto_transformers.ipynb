{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (0.23.0)\n",
      "Collecting accelerate\n",
      "  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/13/9e/ee987874058f2d93006961f6ff49e0bcb60ab9c26709ebe06bfa8707a4d8/accelerate-0.24.1-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-0.24.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from accelerate) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from accelerate) (0.17.3)\n",
      "Requirement already satisfied: filelock in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.2.140)\n",
      "Requirement already satisfied: requests in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jonathancarona/anaconda3/envs/AICH/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.23.0\n",
      "    Uninstalling accelerate-0.23.0:\n",
      "      Successfully uninstalled accelerate-0.23.0\n",
      "Successfully installed accelerate-0.24.1\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8a31b8cc1996</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In the social pyramid of ancient Egypt the pha...</td>\n",
       "      <td>-0.077267</td>\n",
       "      <td>0.424365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8c9411cfc953</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>Aristotle claims that an ideal tragedy should ...</td>\n",
       "      <td>0.559070</td>\n",
       "      <td>-0.634924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4387107feb4d</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The ancient Egyptian system of government was ...</td>\n",
       "      <td>1.376083</td>\n",
       "      <td>2.389443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d720eb53c270</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They put pickle in them to mask the smell of r...</td>\n",
       "      <td>0.297031</td>\n",
       "      <td>-0.168734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e887883b946c</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>\"whenever meat was so spoiled that it could no...</td>\n",
       "      <td>-0.093814</td>\n",
       "      <td>0.503833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id                                               text  \\\n",
       "0  8a31b8cc1996    3b9047  In the social pyramid of ancient Egypt the pha...   \n",
       "1  8c9411cfc953    39c16e  Aristotle claims that an ideal tragedy should ...   \n",
       "2  4387107feb4d    3b9047  The ancient Egyptian system of government was ...   \n",
       "3  d720eb53c270    ebad26  They put pickle in them to mask the smell of r...   \n",
       "4  e887883b946c    ebad26  \"whenever meat was so spoiled that it could no...   \n",
       "\n",
       "    content   wording  \n",
       "0 -0.077267  0.424365  \n",
       "1  0.559070 -0.634924  \n",
       "2  1.376083  2.389443  \n",
       "3  0.297031 -0.168734  \n",
       "4 -0.093814  0.503833  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_df = pd.read_csv('../data/v2/train/train_data.csv')\n",
    "summaries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b9047</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>814d6b</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "1    3b9047  In complete sentences, summarize the structure...   \n",
       "2    814d6b  Summarize how the Third Wave developed over su...   \n",
       "3    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                prompt_title  \\\n",
       "0                 On Tragedy   \n",
       "1  Egyptian Social Structure   \n",
       "2             The Third Wave   \n",
       "3    Excerpt from The Jungle   \n",
       "\n",
       "                                         prompt_text  \n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...  \n",
       "1  Egyptian society was structured like a pyramid...  \n",
       "2  Background \\r\\nThe Third Wave experiment took ...  \n",
       "3  With one member trimming beef in a cannery, an...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_df = pd.read_csv('../kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\n",
    "prompts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8a31b8cc1996</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In the social pyramid of ancient Egypt the pha...</td>\n",
       "      <td>-0.077267</td>\n",
       "      <td>0.424365</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4387107feb4d</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The ancient Egyptian system of government was ...</td>\n",
       "      <td>1.376083</td>\n",
       "      <td>2.389443</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3b784d0a5c8f</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>Nobles were the only ont that could hold gover...</td>\n",
       "      <td>0.467722</td>\n",
       "      <td>-0.085653</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1b2ff4d4edd9</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>They were many different social classes. The p...</td>\n",
       "      <td>-0.012957</td>\n",
       "      <td>-0.409480</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108049c01946</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The ancient Egyptian system of goverment is in...</td>\n",
       "      <td>2.204640</td>\n",
       "      <td>-0.645344</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>d8ae24010bf9</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave experiment was a huge success i...</td>\n",
       "      <td>3.005642</td>\n",
       "      <td>3.226292</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5728</th>\n",
       "      <td>e32a76187192</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed over such a short tim...</td>\n",
       "      <td>0.997243</td>\n",
       "      <td>1.880386</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5729</th>\n",
       "      <td>2c6d06ca1eea</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The experiment developed over such a short per...</td>\n",
       "      <td>-0.693773</td>\n",
       "      <td>-0.490571</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5730</th>\n",
       "      <td>47d4807beb66</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>It was easy for the students to follow this be...</td>\n",
       "      <td>-0.093814</td>\n",
       "      <td>0.503833</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731</th>\n",
       "      <td>52d42283cb1e</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave developed quickly because stude...</td>\n",
       "      <td>1.344145</td>\n",
       "      <td>0.835238</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5732 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        student_id prompt_id  \\\n",
       "0     8a31b8cc1996    3b9047   \n",
       "1     4387107feb4d    3b9047   \n",
       "2     3b784d0a5c8f    3b9047   \n",
       "3     1b2ff4d4edd9    3b9047   \n",
       "4     108049c01946    3b9047   \n",
       "...            ...       ...   \n",
       "5727  d8ae24010bf9    814d6b   \n",
       "5728  e32a76187192    814d6b   \n",
       "5729  2c6d06ca1eea    814d6b   \n",
       "5730  47d4807beb66    814d6b   \n",
       "5731  52d42283cb1e    814d6b   \n",
       "\n",
       "                                                   text   content   wording  \\\n",
       "0     In the social pyramid of ancient Egypt the pha... -0.077267  0.424365   \n",
       "1     The ancient Egyptian system of government was ...  1.376083  2.389443   \n",
       "2     Nobles were the only ont that could hold gover...  0.467722 -0.085653   \n",
       "3     They were many different social classes. The p... -0.012957 -0.409480   \n",
       "4     The ancient Egyptian system of goverment is in...  2.204640 -0.645344   \n",
       "...                                                 ...       ...       ...   \n",
       "5727  The Third Wave experiment was a huge success i...  3.005642  3.226292   \n",
       "5728  The Third Wave developed over such a short tim...  0.997243  1.880386   \n",
       "5729  The experiment developed over such a short per... -0.693773 -0.490571   \n",
       "5730  It was easy for the students to follow this be... -0.093814  0.503833   \n",
       "5731  The third wave developed quickly because stude...  1.344145  0.835238   \n",
       "\n",
       "                                        prompt_question  \\\n",
       "0     In complete sentences, summarize the structure...   \n",
       "1     In complete sentences, summarize the structure...   \n",
       "2     In complete sentences, summarize the structure...   \n",
       "3     In complete sentences, summarize the structure...   \n",
       "4     In complete sentences, summarize the structure...   \n",
       "...                                                 ...   \n",
       "5727  Summarize how the Third Wave developed over su...   \n",
       "5728  Summarize how the Third Wave developed over su...   \n",
       "5729  Summarize how the Third Wave developed over su...   \n",
       "5730  Summarize how the Third Wave developed over su...   \n",
       "5731  Summarize how the Third Wave developed over su...   \n",
       "\n",
       "                   prompt_title  \\\n",
       "0     Egyptian Social Structure   \n",
       "1     Egyptian Social Structure   \n",
       "2     Egyptian Social Structure   \n",
       "3     Egyptian Social Structure   \n",
       "4     Egyptian Social Structure   \n",
       "...                         ...   \n",
       "5727             The Third Wave   \n",
       "5728             The Third Wave   \n",
       "5729             The Third Wave   \n",
       "5730             The Third Wave   \n",
       "5731             The Third Wave   \n",
       "\n",
       "                                            prompt_text  \n",
       "0     Egyptian society was structured like a pyramid...  \n",
       "1     Egyptian society was structured like a pyramid...  \n",
       "2     Egyptian society was structured like a pyramid...  \n",
       "3     Egyptian society was structured like a pyramid...  \n",
       "4     Egyptian society was structured like a pyramid...  \n",
       "...                                                 ...  \n",
       "5727  Background \\r\\nThe Third Wave experiment took ...  \n",
       "5728  Background \\r\\nThe Third Wave experiment took ...  \n",
       "5729  Background \\r\\nThe Third Wave experiment took ...  \n",
       "5730  Background \\r\\nThe Third Wave experiment took ...  \n",
       "5731  Background \\r\\nThe Third Wave experiment took ...  \n",
       "\n",
       "[5732 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(summaries_df, prompts_df, on='prompt_id')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = merged_df.text.tolist()\n",
    "wording = merged_df.wording.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70 Train, 15 Val, 15 Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, wording, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BASE_MODEL = \"bert-base-cased\"\n",
    "LEARNING_RATE = 2e-5\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1719090ef424f109ae3ecb4021a0f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4012 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0008f549a02148358f5a9caabdb2026e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/860 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc79e0822e8b46a3970fbd77c9a76ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/860 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train = Dataset.from_pandas(pd.DataFrame({\n",
    "    'text': X_train,\n",
    "    'wording_score': y_train\n",
    "}))\n",
    "\n",
    "validation = Dataset.from_pandas(pd.DataFrame({\n",
    "    'text': X_val,\n",
    "    'wording_score': y_val\n",
    "}))\n",
    "\n",
    "test = Dataset.from_pandas(pd.DataFrame({\n",
    "    'text': X_test,\n",
    "    'wording_score': y_test\n",
    "}))\n",
    "\n",
    "ds = {\n",
    "    \"train\": train, \n",
    "    \"validation\": validation, \n",
    "    \"test\": test\n",
    "}\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    label = examples[\"wording_score\"] \n",
    "    examples = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "    \n",
    "    # Change this to real number\n",
    "    examples[\"label\"] = float(label)\n",
    "    return examples\n",
    "\n",
    "for split in ds:\n",
    "    ds[split] = ds[split].map(preprocess_function, remove_columns=[\"text\", \"wording_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'label': Value(dtype='float64', id=None)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def compute_metrics_for_regression(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    \n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    r2 = r2_score(labels, logits)\n",
    "    single_squared_errors = ((logits - labels).flatten()**2).tolist()\n",
    "    \n",
    "    # Compute accuracy \n",
    "    # Based on the fact that the rounded score = true score only if |single_squared_errors| < 0.5\n",
    "    accuracy = sum([1 for e in single_squared_errors if e < 0.25]) / len(single_squared_errors)\n",
    "    \n",
    "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/bert-base-cased-regression\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    load_best_model_at_end=True,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "class RegressionTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0][:, 0]\n",
    "        loss = torch.nn.functional.mse_loss(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2881a9845b7a48f196ec18d4597930ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jonathancarona/Documents/AICH/Jonathan_Playground/secondlookinto_transformers.ipynb Cell 16\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jonathancarona/Documents/AICH/Jonathan_Playground/secondlookinto_transformers.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m RegressionTrainer(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jonathancarona/Documents/AICH/Jonathan_Playground/secondlookinto_transformers.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jonathancarona/Documents/AICH/Jonathan_Playground/secondlookinto_transformers.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jonathancarona/Documents/AICH/Jonathan_Playground/secondlookinto_transformers.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics_for_regression,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jonathancarona/Documents/AICH/Jonathan_Playground/secondlookinto_transformers.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jonathancarona/Documents/AICH/Jonathan_Playground/secondlookinto_transformers.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/anaconda3/envs/AICH/lib/python3.11/site-packages/transformers/trainer.py:1591\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1590\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1591\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1592\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1593\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1594\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1595\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1596\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/AICH/lib/python3.11/site-packages/transformers/trainer.py:1892\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1891\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1892\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1894\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1895\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1896\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1897\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1898\u001b[0m ):\n\u001b[1;32m   1899\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1900\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/AICH/lib/python3.11/site-packages/transformers/trainer.py:2787\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m         scaled_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m   2786\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2787\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mbackward(loss)\n\u001b[1;32m   2789\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach() \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/anaconda3/envs/AICH/lib/python3.11/site-packages/accelerate/accelerator.py:1985\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1983\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1984\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1985\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/AICH/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/AICH/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = RegressionTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    compute_metrics=compute_metrics_for_regression,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.eval_dataset=ds[\"test\"]\n",
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AICH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
