\noindent
This project revolved around the Kaggle Challenge: CommonLit - Evaluate Student Summaries. The aim of this challenge was to create a machine learning model, which could accurately assess the quality of summaries written by students in grades 3-12. Using the data provided by the challenge, which contained the summaries of over 7'000 students across four different topics, the team developed three distinct models.\\
The ROUGE-Based Model is a Neural Network, which uses ROUGE metrics as itâ€™s input features. The LightGBM Model uses an array of scores, which can determine readability, complexity and the grade level of a summary. The DeBerta Transformer, a state-of-the-art language model which balances out the two while also considering the specific task the students were asked to capture in their summary.\\
These three models collectively form the final Ensemble Model. Each model independently preprocesses the texts and generates predictions. The Ensemble Model weighs the contributions of each model to produce a final score. The results showcase respectable performance in the Kaggle competition, placing 975th out of a total 2'065 participants.