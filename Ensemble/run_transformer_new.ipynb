{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Transformers\n",
    "This Notebook serves to run our fine-tuned transformer models.\n",
    "All models can be found under models/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is our train data merged with prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     student_id prompt_id                                               text  \\\n0  8a31b8cc1996    3b9047  In the social pyramid of ancient Egypt the pha...   \n1  4387107feb4d    3b9047  The ancient Egyptian system of government was ...   \n2  3b784d0a5c8f    3b9047  Nobles were the only ont that could hold gover...   \n3  1b2ff4d4edd9    3b9047  They were many different social classes. The p...   \n4  108049c01946    3b9047  The ancient Egyptian system of goverment is in...   \n\n    content   wording                                    prompt_question  \\\n0 -0.077267  0.424365  In complete sentences, summarize the structure...   \n1  1.376083  2.389443  In complete sentences, summarize the structure...   \n2  0.467722 -0.085653  In complete sentences, summarize the structure...   \n3 -0.012957 -0.409480  In complete sentences, summarize the structure...   \n4  2.204640 -0.645344  In complete sentences, summarize the structure...   \n\n                prompt_title  \\\n0  Egyptian Social Structure   \n1  Egyptian Social Structure   \n2  Egyptian Social Structure   \n3  Egyptian Social Structure   \n4  Egyptian Social Structure   \n\n                                         prompt_text  \n0  Egyptian society was structured like a pyramid...  \n1  Egyptian society was structured like a pyramid...  \n2  Egyptian society was structured like a pyramid...  \n3  Egyptian society was structured like a pyramid...  \n4  Egyptian society was structured like a pyramid...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8a31b8cc1996</td>\n      <td>3b9047</td>\n      <td>In the social pyramid of ancient Egypt the pha...</td>\n      <td>-0.077267</td>\n      <td>0.424365</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4387107feb4d</td>\n      <td>3b9047</td>\n      <td>The ancient Egyptian system of government was ...</td>\n      <td>1.376083</td>\n      <td>2.389443</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3b784d0a5c8f</td>\n      <td>3b9047</td>\n      <td>Nobles were the only ont that could hold gover...</td>\n      <td>0.467722</td>\n      <td>-0.085653</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1b2ff4d4edd9</td>\n      <td>3b9047</td>\n      <td>They were many different social classes. The p...</td>\n      <td>-0.012957</td>\n      <td>-0.409480</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>108049c01946</td>\n      <td>3b9047</td>\n      <td>The ancient Egyptian system of goverment is in...</td>\n      <td>2.204640</td>\n      <td>-0.645344</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/merged.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a transformer and tokenizer\n",
    "Inside models you have to choose the transformer and then the checkpoint to initialize it\n",
    "\n",
    "Make sure to also select the fitting tokenizer as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Semester 5\\Environments\\ESS - Project\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "('./tokenizers/deberta-v3-base-tokenizer\\\\tokenizer_config.json',\n './tokenizers/deberta-v3-base-tokenizer\\\\special_tokens_map.json',\n './tokenizers/deberta-v3-base-tokenizer\\\\spm.model',\n './tokenizers/deberta-v3-base-tokenizer\\\\added_tokens.json',\n './tokenizers/deberta-v3-base-tokenizer\\\\tokenizer.json')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the path for the transformer and tokenizer you want to run\n",
    "#TRANSFORMER_PATH = './models/deberta-v3-large-epoch-3/checkpoint-1504'\n",
    "TRANSFORMER_PATH = './models/deberta-v3-base/deberta-v3-base/checkpoint-4012'\n",
    "#TOKENIZER_PATH = 'microsoft/deberta-v3-large'\n",
    "TOKENIZER_PATH = 'microsoft/deberta-v3-base'\n",
    "TOKENIZER_NAME = TOKENIZER_PATH.split('/')[-1] + '-tokenizer'\n",
    "MAX_LENGTH = 1024\n",
    "\n",
    "\n",
    "transformer = AutoModelForSequenceClassification.from_pretrained(TRANSFORMER_PATH, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "tokenizer.save_pretrained(f'./tokenizers/{TOKENIZER_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize a single data point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    1, 38081,   262,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "def tokenize_encode(text, prompt_question, prompt_text):\n",
    "    prompt = f'Evaluate the content and wording score of this summary: {tokenizer.sep_token} {text} {tokenizer.sep_token} The summary must answer the following prompt: {prompt_question} {tokenizer.sep_token} The prompt is related towards the following original text: {prompt_text}'\n",
    "\n",
    "    encoded = tokenizer(\n",
    "        prompt, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        # Adjust max length to fitted model\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    return encoded\n",
    "\n",
    "# Replace with summary text\n",
    "text = data.text[0]\n",
    "# Replace with prompt_question\n",
    "prompt_question = data.prompt_question[0]\n",
    "# Replace with prompt_text\n",
    "prompt_text = data.prompt_text[0]\n",
    "\n",
    "print(tokenize_encode(text, prompt_question, prompt_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the transformer for a single data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[0.10300210118293762, 0.34845027327537537]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = transformer(**tokenize_encode(text, prompt_question, prompt_text))\n",
    "output.logits.reshape(-1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the transformer on pandas frame\n",
    "Adapt the code for your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:29<00:00,  5.81s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "    content   wording\n0  0.103002  0.348450\n1  1.332854  1.272060\n2  0.460646 -0.344013\n3 -0.159789 -0.498713\n4  1.436758 -0.587502",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.103002</td>\n      <td>0.348450</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.332854</td>\n      <td>1.272060</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.460646</td>\n      <td>-0.344013</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.159789</td>\n      <td>-0.498713</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.436758</td>\n      <td>-0.587502</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_preds = []\n",
    "wording_preds = []\n",
    "\n",
    "# Replace data for your own data. Here we use the first 5 rows from the merged.csv\n",
    "for index, row in tqdm(data[:5].iterrows(), total=data[:5].shape[0]):\n",
    "    inputs = tokenize_encode(row.text, row.prompt_question, row.prompt_text)\n",
    "    # Content predicting\n",
    "    outputs = transformer(**inputs).logits.reshape(-1).tolist()\n",
    "    \n",
    "    content_preds.append(outputs[0])\n",
    "    wording_preds.append(outputs[1])\n",
    "\n",
    "submission_df = pd.DataFrame({'content': content_preds, 'wording': wording_preds})\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- ------------\n",
      "absl-py                   2.0.0\n",
      "aiohttp                   3.8.6\n",
      "aiosignal                 1.3.1\n",
      "alembic                   1.13.0\n",
      "anyio                     4.0.0\n",
      "appdirs                   1.4.4\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.0\n",
      "async-lru                 2.0.4\n",
      "async-timeout             4.0.3\n",
      "attrs                     23.1.0\n",
      "Babel                     2.13.0\n",
      "backcall                  0.2.0\n",
      "beautifulsoup4            4.12.2\n",
      "bleach                    6.0.0\n",
      "certifi                   2023.7.22\n",
      "cffi                      1.16.0\n",
      "charset-normalizer        3.3.0\n",
      "click                     8.1.7\n",
      "colorama                  0.4.6\n",
      "colorlog                  6.7.0\n",
      "comm                      0.1.4\n",
      "contourpy                 1.1.1\n",
      "cycler                    0.12.0\n",
      "datasets                  2.14.5\n",
      "debugpy                   1.8.0\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "dill                      0.3.7\n",
      "docker-pycreds            0.4.0\n",
      "evaluate                  0.4.1\n",
      "executing                 2.0.0\n",
      "fastjsonschema            2.18.1\n",
      "filelock                  3.12.4\n",
      "fonttools                 4.43.0\n",
      "fqdn                      1.5.1\n",
      "frozenlist                1.4.0\n",
      "fsspec                    2023.6.0\n",
      "gensim                    4.3.2\n",
      "gitdb                     4.0.11\n",
      "GitPython                 3.1.40\n",
      "greenlet                  3.0.1\n",
      "huggingface-hub           0.17.3\n",
      "idna                      3.4\n",
      "ipykernel                 6.25.2\n",
      "ipython                   8.16.1\n",
      "ipython-genutils          0.2.0\n",
      "ipywidgets                8.1.1\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.1\n",
      "Jinja2                    3.1.2\n",
      "joblib                    1.3.2\n",
      "json5                     0.9.14\n",
      "jsonpointer               2.4\n",
      "jsonschema                4.19.1\n",
      "jsonschema-specifications 2023.7.1\n",
      "jupyter                   1.0.0\n",
      "jupyter_client            8.3.1\n",
      "jupyter-console           6.6.3\n",
      "jupyter_core              5.3.2\n",
      "jupyter-events            0.7.0\n",
      "jupyter-lsp               2.2.0\n",
      "jupyter_server            2.7.3\n",
      "jupyter_server_terminals  0.4.4\n",
      "jupyterlab                4.0.6\n",
      "jupyterlab-pygments       0.2.2\n",
      "jupyterlab_server         2.25.0\n",
      "jupyterlab-widgets        3.0.9\n",
      "kaleido                   0.2.1\n",
      "kiwisolver                1.4.5\n",
      "lightgbm                  4.1.0\n",
      "Mako                      1.3.0\n",
      "MarkupSafe                2.1.3\n",
      "matplotlib                3.8.0\n",
      "matplotlib-inline         0.1.6\n",
      "mistune                   3.0.2\n",
      "mpmath                    1.3.0\n",
      "multidict                 6.0.4\n",
      "multiprocess              0.70.15\n",
      "nbclient                  0.8.0\n",
      "nbconvert                 7.9.1\n",
      "nbformat                  5.9.2\n",
      "nest-asyncio              1.5.8\n",
      "networkx                  3.1\n",
      "nltk                      3.8.1\n",
      "notebook                  7.0.4\n",
      "notebook_shim             0.2.3\n",
      "numpy                     1.26.0\n",
      "optuna                    3.4.0\n",
      "overrides                 7.4.0\n",
      "packaging                 23.2\n",
      "pandas                    2.1.1\n",
      "pandocfilters             1.5.0\n",
      "parso                     0.8.3\n",
      "pathtools                 0.1.2\n",
      "pickleshare               0.7.5\n",
      "Pillow                    10.0.1\n",
      "pip                       23.3.1\n",
      "platformdirs              3.11.0\n",
      "plotly                    5.18.0\n",
      "prometheus-client         0.17.1\n",
      "prompt-toolkit            3.0.39\n",
      "protobuf                  4.24.4\n",
      "psutil                    5.9.5\n",
      "pure-eval                 0.2.2\n",
      "pyarrow                   13.0.0\n",
      "pybind11                  2.11.1\n",
      "pycparser                 2.21\n",
      "Pygments                  2.16.1\n",
      "pyparsing                 3.1.1\n",
      "pyphen                    0.14.0\n",
      "python-dateutil           2.8.2\n",
      "python-json-logger        2.0.7\n",
      "pytz                      2023.3.post1\n",
      "pywin32                   306\n",
      "pywinpty                  2.0.11\n",
      "PyYAML                    6.0.1\n",
      "pyzmq                     25.1.1\n",
      "qtconsole                 5.4.4\n",
      "QtPy                      2.4.0\n",
      "referencing               0.30.2\n",
      "regex                     2023.10.3\n",
      "requests                  2.31.0\n",
      "responses                 0.18.0\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rouge                     1.0.1\n",
      "rouge-metric              1.0.1\n",
      "rouge-score               0.1.2\n",
      "rpds-py                   0.10.3\n",
      "safetensors               0.4.0\n",
      "scikit-learn              1.3.1\n",
      "scipy                     1.11.3\n",
      "seaborn                   0.13.0\n",
      "Send2Trash                1.8.2\n",
      "sentencepiece             0.1.99\n",
      "sentry-sdk                1.32.0\n",
      "setproctitle              1.3.3\n",
      "setuptools                68.2.2\n",
      "six                       1.16.0\n",
      "sklearn                   0.0\n",
      "smart-open                6.4.0\n",
      "smmap                     5.0.1\n",
      "sniffio                   1.3.0\n",
      "soupsieve                 2.5\n",
      "SQLAlchemy                2.0.23\n",
      "stack-data                0.6.3\n",
      "sympy                     1.12\n",
      "tenacity                  8.2.3\n",
      "terminado                 0.17.1\n",
      "textstat                  0.7.3\n",
      "threadpoolctl             3.2.0\n",
      "tinycss2                  1.2.1\n",
      "tokenizers                0.14.1\n",
      "torch                     2.1.0\n",
      "tornado                   6.3.3\n",
      "tqdm                      4.66.1\n",
      "traitlets                 5.11.2\n",
      "transformers              4.34.1\n",
      "types-python-dateutil     2.8.19.14\n",
      "typing_extensions         4.8.0\n",
      "tzdata                    2023.3\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.0.6\n",
      "wandb                     0.15.12\n",
      "wcwidth                   0.2.8\n",
      "webcolors                 1.13\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.6.3\n",
      "wheel                     0.37.1\n",
      "widgetsnbextension        4.0.9\n",
      "xxhash                    3.4.1\n",
      "yarl                      1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AICH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
