{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Josef"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import Tensor, nn, cat, flatten\n",
    "from nltk.util import ngrams\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:30.462481Z",
     "iopub.execute_input": "2023-11-01T13:28:30.463339Z",
     "iopub.status.idle": "2023-11-01T13:28:36.882685Z",
     "shell.execute_reply.started": "2023-11-01T13:28:30.463278Z",
     "shell.execute_reply": "2023-11-01T13:28:36.881451Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:31:34.914137300Z",
     "start_time": "2023-11-08T16:31:34.817132200Z"
    }
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "_PATH = '/kaggle/input/commonlit-evaluate-student-summaries'"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:36.887609Z",
     "iopub.execute_input": "2023-11-01T13:28:36.88813Z",
     "iopub.status.idle": "2023-11-01T13:28:36.8939Z",
     "shell.execute_reply.started": "2023-11-01T13:28:36.888097Z",
     "shell.execute_reply": "2023-11-01T13:28:36.892462Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.584943Z",
     "start_time": "2023-11-08T16:17:35.572943900Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def _get_path():\n",
    "    if os.name == 'nt':\n",
    "        return f'.{_PATH}'\n",
    "    elif os.name == 'posix':\n",
    "        return _PATH"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:36.895645Z",
     "iopub.execute_input": "2023-11-01T13:28:36.896006Z",
     "iopub.status.idle": "2023-11-01T13:28:36.910611Z",
     "shell.execute_reply.started": "2023-11-01T13:28:36.895975Z",
     "shell.execute_reply": "2023-11-01T13:28:36.908961Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.621940200Z",
     "start_time": "2023-11-08T16:17:35.584943Z"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def setup():\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print('\\x1b[0;32mGPU is available.\\x1b[0m')\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print('\\x1b[0;34mGPU not available. CPU used.\\x1b[0m')\n",
    "\n",
    "    return device, _get_path()"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:36.913894Z",
     "iopub.execute_input": "2023-11-01T13:28:36.91429Z",
     "iopub.status.idle": "2023-11-01T13:28:36.925787Z",
     "shell.execute_reply.started": "2023-11-01T13:28:36.91426Z",
     "shell.execute_reply": "2023-11-01T13:28:36.924796Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.622979100Z",
     "start_time": "2023-11-08T16:17:35.598944900Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_data(path=None):\n",
    "    if path is None:\n",
    "        path = _get_path()\n",
    "\n",
    "    summaries_df = pd.read_csv(f'{path}/summaries_train.csv')\n",
    "    prompts_df = pd.read_csv(f'{path}/prompts_train.csv')\n",
    "    return summaries_df, prompts_df"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:36.927057Z",
     "iopub.execute_input": "2023-11-01T13:28:36.928055Z",
     "iopub.status.idle": "2023-11-01T13:28:36.940137Z",
     "shell.execute_reply.started": "2023-11-01T13:28:36.928013Z",
     "shell.execute_reply": "2023-11-01T13:28:36.938884Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.639942500Z",
     "start_time": "2023-11-08T16:17:35.613941100Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_prompt(summary, prompts_df):\n",
    "    prompt = prompts_df.loc[prompts_df.prompt_id == summary.prompt_id]\n",
    "    return prompt.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:36.941611Z",
     "iopub.execute_input": "2023-11-01T13:28:36.941994Z",
     "iopub.status.idle": "2023-11-01T13:28:36.953828Z",
     "shell.execute_reply.started": "2023-11-01T13:28:36.941962Z",
     "shell.execute_reply": "2023-11-01T13:28:36.952624Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.645954600Z",
     "start_time": "2023-11-08T16:17:35.628980600Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def mcrmse(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(\"Shapes of y_true and y_pred must be the same.\")\n",
    "    rmse_values = np.sqrt(np.mean((y_true - y_pred)**2, axis=0))\n",
    "    mcrmse = np.mean(rmse_values)\n",
    "\n",
    "    return mcrmse"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:36.955431Z",
     "iopub.execute_input": "2023-11-01T13:28:36.95607Z",
     "iopub.status.idle": "2023-11-01T13:28:36.969428Z",
     "shell.execute_reply.started": "2023-11-01T13:28:36.956036Z",
     "shell.execute_reply": "2023-11-01T13:28:36.968104Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.677941500Z",
     "start_time": "2023-11-08T16:17:35.647951600Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ROUGE-Scorers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "Score = collections.namedtuple('Score', ['precision', 'recall', 'fmeasure'])"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:36.971301Z",
     "iopub.execute_input": "2023-11-01T13:28:36.971726Z",
     "iopub.status.idle": "2023-11-01T13:28:36.983529Z",
     "shell.execute_reply.started": "2023-11-01T13:28:36.97169Z",
     "shell.execute_reply": "2023-11-01T13:28:36.981941Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.678941400Z",
     "start_time": "2023-11-08T16:17:35.661942400Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:36.984996Z",
     "iopub.execute_input": "2023-11-01T13:28:36.985852Z",
     "iopub.status.idle": "2023-11-01T13:28:36.997067Z",
     "shell.execute_reply.started": "2023-11-01T13:28:36.985815Z",
     "shell.execute_reply": "2023-11-01T13:28:36.996012Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.692943200Z",
     "start_time": "2023-11-08T16:17:35.674958800Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_sents(text):\n",
    "    sents = sent_tokenize(text)\n",
    "    sents = [x for x in sents if len(x)]\n",
    "    return sents"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:37.00459Z",
     "iopub.execute_input": "2023-11-01T13:28:37.007835Z",
     "iopub.status.idle": "2023-11-01T13:28:37.02015Z",
     "shell.execute_reply.started": "2023-11-01T13:28:37.007765Z",
     "shell.execute_reply": "2023-11-01T13:28:37.018953Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.732978500Z",
     "start_time": "2023-11-08T16:17:35.689941200Z"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def _lcs_table(ref, can):\n",
    "    \"\"\"Create 2-d LCS score table.\"\"\"\n",
    "    rows = len(ref)\n",
    "    cols = len(can)\n",
    "    lcs_table = np.zeros((rows + 1, cols + 1))\n",
    "    for i in range(1, rows + 1):\n",
    "        for j in range(1, cols + 1):\n",
    "            if ref[i - 1] == can[j - 1]:\n",
    "                lcs_table[i][j] = lcs_table[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                lcs_table[i][j] = max(lcs_table[i - 1][j], lcs_table[i][j - 1])\n",
    "    return lcs_table"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:37.021815Z",
     "iopub.execute_input": "2023-11-01T13:28:37.023189Z",
     "iopub.status.idle": "2023-11-01T13:28:37.035505Z",
     "shell.execute_reply.started": "2023-11-01T13:28:37.023141Z",
     "shell.execute_reply": "2023-11-01T13:28:37.034259Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.734989600Z",
     "start_time": "2023-11-08T16:17:35.707944400Z"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def _backtrack_norec(t, ref, can):\n",
    "    \"\"\"Read out LCS.\"\"\"\n",
    "    i = len(ref)\n",
    "    j = len(can)\n",
    "    lcs = []\n",
    "    while i > 0 and j > 0:\n",
    "        if ref[i - 1] == can[j - 1]:\n",
    "            lcs.insert(0, i - 1)\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif t[i][j - 1] > t[i - 1][j]:\n",
    "            j -= 1\n",
    "        else:\n",
    "            i -= 1\n",
    "    return lcs"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:37.037263Z",
     "iopub.execute_input": "2023-11-01T13:28:37.038419Z",
     "iopub.status.idle": "2023-11-01T13:28:37.057623Z",
     "shell.execute_reply.started": "2023-11-01T13:28:37.038374Z",
     "shell.execute_reply": "2023-11-01T13:28:37.055781Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.737988700Z",
     "start_time": "2023-11-08T16:17:35.722948100Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def lcs_ind(ref, can):\n",
    "    \"\"\"Returns one of the longest lcs.\"\"\"\n",
    "    t = _lcs_table(ref, can)\n",
    "    return _backtrack_norec(t, ref, can)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:37.059506Z",
     "iopub.execute_input": "2023-11-01T13:28:37.060345Z",
     "iopub.status.idle": "2023-11-01T13:28:37.071904Z",
     "shell.execute_reply.started": "2023-11-01T13:28:37.060299Z",
     "shell.execute_reply": "2023-11-01T13:28:37.070584Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.752943900Z",
     "start_time": "2023-11-08T16:17:35.735940900Z"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def _find_union(lcs_list):\n",
    "    \"\"\"Finds union LCS given a list of LCS.\"\"\"\n",
    "    return sorted(list(set().union(*lcs_list)))"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:37.073255Z",
     "iopub.execute_input": "2023-11-01T13:28:37.074294Z",
     "iopub.status.idle": "2023-11-01T13:28:37.0872Z",
     "shell.execute_reply.started": "2023-11-01T13:28:37.074257Z",
     "shell.execute_reply": "2023-11-01T13:28:37.085397Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.779982100Z",
     "start_time": "2023-11-08T16:17:35.754986600Z"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def _union_lcs(ref, c_list):\n",
    "    lcs_list = [lcs_ind(ref, c) for c in c_list]\n",
    "    return [ref[i] for i in _find_union(lcs_list)]"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:37.089325Z",
     "iopub.execute_input": "2023-11-01T13:28:37.08983Z",
     "iopub.status.idle": "2023-11-01T13:28:37.102631Z",
     "shell.execute_reply.started": "2023-11-01T13:28:37.089792Z",
     "shell.execute_reply": "2023-11-01T13:28:37.101224Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.782978800Z",
     "start_time": "2023-11-08T16:17:35.768941600Z"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def rouge_n(target, prediction, n):\n",
    "    target_tokens = tokenize(target)\n",
    "    prediction_tokens = tokenize(prediction)\n",
    "\n",
    "    target_ngrams = collections.Counter(ngrams(target_tokens, n))\n",
    "    prediction_ngrams = collections.Counter(ngrams(prediction_tokens, n))\n",
    "\n",
    "    intersection_ngrams_count = 0\n",
    "    for ngram in target_ngrams:\n",
    "        intersection_ngrams_count += min(target_ngrams[ngram],\n",
    "                                         prediction_ngrams[ngram])\n",
    "    target_ngrams_count = sum(target_ngrams.values())\n",
    "    prediction_ngrams_count = sum(prediction_ngrams.values())\n",
    "\n",
    "    precision = intersection_ngrams_count / max(prediction_ngrams_count, 1)\n",
    "    recall = intersection_ngrams_count / max(target_ngrams_count, 1)\n",
    "\n",
    "    if precision + recall > 0:\n",
    "        fmeasure = 2 * precision * recall / (precision + recall)\n",
    "    else:\n",
    "        fmeasure = 0.0\n",
    "\n",
    "    return pd.Series({'precision': precision, 'recall': recall, 'fmeasure': fmeasure})"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:37.104421Z",
     "iopub.execute_input": "2023-11-01T13:28:37.105042Z",
     "iopub.status.idle": "2023-11-01T13:28:37.118388Z",
     "shell.execute_reply.started": "2023-11-01T13:28:37.105001Z",
     "shell.execute_reply": "2023-11-01T13:28:37.117045Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.797979900Z",
     "start_time": "2023-11-08T16:17:35.785941400Z"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def rouge_l(target, prediction):\n",
    "    target_tokens = tokenize(target)\n",
    "    prediction_tokens = tokenize(prediction)\n",
    "\n",
    "    if not target_tokens or not prediction_tokens:\n",
    "        return pd.Series({'precision': 0, 'recall': 0, 'fmeasure': 0})\n",
    "\n",
    "    lcs_table = _lcs_table(target_tokens, prediction_tokens)\n",
    "\n",
    "    lcs_length = lcs_table[-1][-1]\n",
    "\n",
    "    precision = lcs_length / len(prediction_tokens)\n",
    "    recall = lcs_length / len(target_tokens)\n",
    "    if precision + recall > 0:\n",
    "        fmeasure = 2 * precision * recall / (precision + recall)\n",
    "    else:\n",
    "        fmeasure = 0.0\n",
    "\n",
    "    return pd.Series({'precision': precision, 'recall': recall, 'fmeasure': fmeasure})"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:37.120109Z",
     "iopub.execute_input": "2023-11-01T13:28:37.1205Z",
     "iopub.status.idle": "2023-11-01T13:28:37.136777Z",
     "shell.execute_reply.started": "2023-11-01T13:28:37.120467Z",
     "shell.execute_reply": "2023-11-01T13:28:37.135543Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.831970500Z",
     "start_time": "2023-11-08T16:17:35.800944100Z"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def rouge_lsum(target, prediction):\n",
    "    target_tokens_list = [\n",
    "        tokenize(s) for s in get_sents(target)]\n",
    "    prediction_tokens_list = [\n",
    "        tokenize(s) for s in get_sents(prediction)]\n",
    "\n",
    "    if not target_tokens_list or not prediction_tokens_list:\n",
    "        return pd.Series({'precision': 0, 'recall': 0, 'fmeasure': 0})\n",
    "\n",
    "    m = sum(map(len, target_tokens_list))\n",
    "    n = sum(map(len, prediction_tokens_list))\n",
    "    if not n or not m:\n",
    "        return pd.Series({'precision': 0, 'recall': 0, 'fmeasure': 0})\n",
    "\n",
    "    # get token counts to prevent double counting\n",
    "    token_cnts_r = collections.Counter()\n",
    "    token_cnts_c = collections.Counter()\n",
    "    for s in target_tokens_list:\n",
    "        # s is a list of tokens\n",
    "        token_cnts_r.update(s)\n",
    "    for s in prediction_tokens_list:\n",
    "        token_cnts_c.update(s)\n",
    "\n",
    "    hits = 0\n",
    "    for r in target_tokens_list:\n",
    "        lcs = _union_lcs(r, prediction_tokens_list)\n",
    "        # Prevent double-counting:\n",
    "        # The paper describes just computing hits += len(_union_lcs()),\n",
    "        # but the implementation prevents double counting\n",
    "        for t in lcs:\n",
    "            if token_cnts_c[t] > 0 and token_cnts_r[t] > 0:\n",
    "                hits += 1\n",
    "                token_cnts_c[t] -= 1\n",
    "                token_cnts_r[t] -= 1\n",
    "\n",
    "    recall = hits / m\n",
    "    precision = hits / n\n",
    "    if precision + recall > 0:\n",
    "        fmeasure = 2 * precision * recall / (precision + recall)\n",
    "    else:\n",
    "        fmeasure = 0.0\n",
    "    return pd.Series({'precision': precision, 'recall': recall, 'fmeasure': fmeasure})"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:37.138585Z",
     "iopub.execute_input": "2023-11-01T13:28:37.138976Z",
     "iopub.status.idle": "2023-11-01T13:28:37.154235Z",
     "shell.execute_reply.started": "2023-11-01T13:28:37.138943Z",
     "shell.execute_reply": "2023-11-01T13:28:37.152552Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.832943300Z",
     "start_time": "2023-11-08T16:17:35.816965500Z"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess(summaries, prompts):\n",
    "    tqdm.pandas()\n",
    "\n",
    "    prompt_columns = ['prompt_text', 'prompt_title', 'prompt_question']\n",
    "\n",
    "    merged_df = summaries.merge(prompts, 'inner', 'prompt_id')\n",
    "\n",
    "    print(\"Scores are being calculated. Please stand by...\")\n",
    "    print('rouge_1')\n",
    "    merged_df[['rouge1_recall', 'rouge1_precision', 'rouge1_fmeasure']] = merged_df[['text', 'prompt_text']].progress_apply(lambda row: rouge_n(row.prompt_text, row.text, 1), axis=1, result_type='expand')\n",
    "    print('rouge_2')\n",
    "    merged_df[['rouge2_recall', 'rouge2_precision', 'rouge2_fmeasure']] = merged_df[['text', 'prompt_text']].progress_apply(lambda row: rouge_n(row.prompt_text, row.text, 2), axis=1, result_type='expand')\n",
    "    print('rouge_l')\n",
    "    merged_df[['rougeL_recall', 'rougeL_precision', 'rougeL_fmeasure']] = merged_df[['text', 'prompt_text']].progress_apply(lambda row: rouge_l(row.prompt_text, row.text), axis=1, result_type='expand')\n",
    "    print('rouge_l_sum')\n",
    "    merged_df[['rougeLsum_recall', 'rougeLsum_precision', 'rougeLsum_fmeasure']] = merged_df[['text', 'prompt_text']].progress_apply(lambda row: rouge_lsum(row.prompt_text, row.text), axis=1, result_type='expand')\n",
    "\n",
    "    summaries = merged_df.drop(prompt_columns, axis=1)\n",
    "    return summaries, prompts"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:37.156483Z",
     "iopub.execute_input": "2023-11-01T13:28:37.157673Z",
     "iopub.status.idle": "2023-11-01T13:28:37.175007Z",
     "shell.execute_reply.started": "2023-11-01T13:28:37.157632Z",
     "shell.execute_reply": "2023-11-01T13:28:37.173611Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.846940600Z",
     "start_time": "2023-11-08T16:17:35.832943300Z"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_scores(row):\n",
    "    scores = []\n",
    "    for score in ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']:\n",
    "        scores.append((row[f'{score}_precision'],\n",
    "                       row[f'{score}_recall'],\n",
    "                       row[f'{score}_fmeasure']))\n",
    "\n",
    "    scores = torch.Tensor(scores)\n",
    "    scores = flatten(scores)\n",
    "    return scores"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:37.176743Z",
     "iopub.execute_input": "2023-11-01T13:28:37.177673Z",
     "iopub.status.idle": "2023-11-01T13:28:37.195729Z",
     "shell.execute_reply.started": "2023-11-01T13:28:37.177635Z",
     "shell.execute_reply": "2023-11-01T13:28:37.194483Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.876951800Z",
     "start_time": "2023-11-08T16:17:35.850943300Z"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, summary_len_mean, summary_len_std):\n",
    "        super().__init__()\n",
    "\n",
    "        self.summary_len_mean = summary_len_mean\n",
    "        self.summary_len_std = summary_len_std\n",
    "\n",
    "        self.scores = ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
    "        input_dim = 4*3 + 1\n",
    "\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.non_lin = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.device = 'cpu'\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, prompt_text, summary_text, scores):\n",
    "        #scores = self._calculate_rouge_scores(prompt_text, summary_text)\n",
    "        #scores = flatten(scores)\n",
    "\n",
    "        summary_len_norm = self._summary_len_norm(summary_text)\n",
    "\n",
    "        result = cat((scores, summary_len_norm))\n",
    "\n",
    "        result = self.layer1(result)\n",
    "        result = self.non_lin(result)\n",
    "        result = self.layer2(result)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _calculate_rouge_scores(self, prompt_text, summary_text):\n",
    "\n",
    "        scores = [\n",
    "            rouge_n(prompt_text, summary_text, 1),\n",
    "            rouge_n(prompt_text, summary_text, 2),\n",
    "            rouge_l(prompt_text, summary_text),\n",
    "            rouge_lsum(prompt_text, summary_text)\n",
    "        ]\n",
    "\n",
    "        return Tensor(scores).to(self.device)\n",
    "\n",
    "    def _summary_len_norm(self, summary_text):\n",
    "        zscore = (len(summary_text) - self.summary_len_mean) / self.summary_len_std\n",
    "        return Tensor((zscore,)).to(self.device)\n",
    "\n",
    "\n",
    "    def to(self, device, *args, **kwargs):\n",
    "        super().to(device, *args, **kwargs)\n",
    "        self.device = device\n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:37.198055Z",
     "iopub.execute_input": "2023-11-01T13:28:37.198598Z",
     "iopub.status.idle": "2023-11-01T13:28:37.218051Z",
     "shell.execute_reply.started": "2023-11-01T13:28:37.198556Z",
     "shell.execute_reply": "2023-11-01T13:28:37.216796Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.878950400Z",
     "start_time": "2023-11-08T16:17:35.866943900Z"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "device, path = setup()\n",
    "summaries_df, prompts_df = get_data(path)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:37.219805Z",
     "iopub.execute_input": "2023-11-01T13:28:37.221366Z",
     "iopub.status.idle": "2023-11-01T13:28:37.371547Z",
     "shell.execute_reply.started": "2023-11-01T13:28:37.221321Z",
     "shell.execute_reply": "2023-11-01T13:28:37.370021Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:17:35.953986500Z",
     "start_time": "2023-11-08T16:17:35.877959100Z"
    }
   },
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0;34mGPU not available. CPU used.\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "summaries_df, prompts_df = preprocess(summaries_df, prompts_df)\n",
    "summaries_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T13:28:37.373763Z",
     "iopub.execute_input": "2023-11-01T13:28:37.374313Z",
     "iopub.status.idle": "2023-11-01T14:03:27.153188Z",
     "shell.execute_reply.started": "2023-11-01T13:28:37.374271Z",
     "shell.execute_reply": "2023-11-01T14:03:27.151883Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:30:21.516269700Z",
     "start_time": "2023-11-08T16:17:35.954943600Z"
    }
   },
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores are being calculated. Please stand by...\n",
      "rouge_1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5732 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae03754b4a9c481e98bd04ec6497bf97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge_2\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5732 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b9fdb11cd724a1a9482f7f8722f6d29"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge_l\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5732 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62e75b64cec84757a153967a1bb7ce48"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge_l_sum\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5732 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec234096966941ef843dbfaf9626f63a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Index(['student_id', 'prompt_id', 'text', 'content', 'wording',\n       'rouge1_recall', 'rouge1_precision', 'rouge1_fmeasure', 'rouge2_recall',\n       'rouge2_precision', 'rouge2_fmeasure', 'rougeL_recall',\n       'rougeL_precision', 'rougeL_fmeasure', 'rougeLsum_recall',\n       'rougeLsum_precision', 'rougeLsum_fmeasure'],\n      dtype='object')"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "hidden_dim = 64\n",
    "#output_dim = 2\n",
    "output_dim = 1"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T14:03:27.155207Z",
     "iopub.execute_input": "2023-11-01T14:03:27.155723Z",
     "iopub.status.idle": "2023-11-01T14:03:27.163462Z",
     "shell.execute_reply.started": "2023-11-01T14:03:27.155679Z",
     "shell.execute_reply": "2023-11-01T14:03:27.162556Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-11-08T16:30:21.582276300Z"
    }
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "text_len_mean = summaries_df.text.apply(len).mean()\n",
    "text_len_std  = summaries_df.text.apply(len).std()"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T14:03:27.164962Z",
     "iopub.execute_input": "2023-11-01T14:03:27.165686Z",
     "iopub.status.idle": "2023-11-01T14:03:27.193003Z",
     "shell.execute_reply.started": "2023-11-01T14:03:27.165653Z",
     "shell.execute_reply": "2023-11-01T14:03:27.192073Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-11-08T16:30:21.584278500Z"
    }
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = Model(hidden_dim, output_dim, text_len_mean, text_len_std)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T14:03:27.194616Z",
     "iopub.execute_input": "2023-11-01T14:03:27.195243Z",
     "iopub.status.idle": "2023-11-01T14:03:27.256126Z",
     "shell.execute_reply.started": "2023-11-01T14:03:27.195211Z",
     "shell.execute_reply": "2023-11-01T14:03:27.25514Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-11-08T16:30:21.588276600Z"
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer=torch.optim.Adam"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T14:03:27.257646Z",
     "iopub.execute_input": "2023-11-01T14:03:27.258211Z",
     "iopub.status.idle": "2023-11-01T14:03:27.262431Z",
     "shell.execute_reply.started": "2023-11-01T14:03:27.25816Z",
     "shell.execute_reply": "2023-11-01T14:03:27.261631Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:30:21.596277400Z",
     "start_time": "2023-11-08T16:30:21.591270100Z"
    }
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "optimizer = optimizer(list(model.parameters()))\n",
    "optimizer.lr = learning_rate"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T14:03:27.267921Z",
     "iopub.execute_input": "2023-11-01T14:03:27.268472Z",
     "iopub.status.idle": "2023-11-01T14:03:27.277646Z",
     "shell.execute_reply.started": "2023-11-01T14:03:27.268441Z",
     "shell.execute_reply": "2023-11-01T14:03:27.276706Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:30:21.607276Z",
     "start_time": "2023-11-08T16:30:21.594277200Z"
    }
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Training...\")"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T14:03:27.278923Z",
     "iopub.execute_input": "2023-11-01T14:03:27.279437Z",
     "iopub.status.idle": "2023-11-01T14:03:27.294265Z",
     "shell.execute_reply.started": "2023-11-01T14:03:27.279407Z",
     "shell.execute_reply": "2023-11-01T14:03:27.293083Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:30:21.700388500Z",
     "start_time": "2023-11-08T16:30:21.597275900Z"
    }
   },
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\", end=\"\\r\")\n",
    "\n",
    "    summaries_df = summaries_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for index, summary in summaries_df.iterrows():\n",
    "\n",
    "        prompt = get_prompt(summary, prompts_df)\n",
    "        scores = get_scores(summary)\n",
    "\n",
    "        #target = Tensor([summary.content, summary.wording]).to(device)\n",
    "        target = Tensor([summary.content]).to(device)\n",
    "\n",
    "        predictions = model(prompt.prompt_text, summary.text, scores)\n",
    "        loss = criterion(predictions, target)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_true.append([*(float(x) for x in target)])\n",
    "        y_pred.append([*(float(x) for x in predictions)])"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T14:03:27.295807Z",
     "iopub.execute_input": "2023-11-01T14:03:27.296164Z",
     "iopub.status.idle": "2023-11-01T14:05:31.172996Z",
     "shell.execute_reply.started": "2023-11-01T14:03:27.296135Z",
     "shell.execute_reply": "2023-11-01T14:05:31.171604Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:31:34.487132600Z",
     "start_time": "2023-11-08T16:30:21.616270800Z"
    }
   },
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\r"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T14:05:31.17462Z",
     "iopub.execute_input": "2023-11-01T14:05:31.175049Z",
     "iopub.status.idle": "2023-11-01T14:05:31.182242Z",
     "shell.execute_reply.started": "2023-11-01T14:05:31.17501Z",
     "shell.execute_reply": "2023-11-01T14:05:31.180868Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:31:34.516133800Z",
     "start_time": "2023-11-08T16:31:34.490134500Z"
    }
   },
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "mse = mean_squared_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"MCRMSE: {mcrmse(y_true, y_pred):.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"R2:  {r2:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T14:05:31.18406Z",
     "iopub.execute_input": "2023-11-01T14:05:31.1845Z",
     "iopub.status.idle": "2023-11-01T14:05:31.236613Z",
     "shell.execute_reply.started": "2023-11-01T14:05:31.184461Z",
     "shell.execute_reply": "2023-11-01T14:05:31.235287Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:31:34.554132700Z",
     "start_time": "2023-11-08T16:31:34.503132Z"
    }
   },
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCRMSE: 0.4581\n",
      "MSE: 0.2098\n",
      "R2:  0.8069\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_prompts_df = pd.read_csv(f'{path}/prompts_test.csv')\n",
    "test_summaries_df = pd.read_csv(f'{path}/summaries_test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T14:05:31.237938Z",
     "iopub.execute_input": "2023-11-01T14:05:31.238287Z",
     "iopub.status.idle": "2023-11-01T14:05:31.267245Z",
     "shell.execute_reply.started": "2023-11-01T14:05:31.238259Z",
     "shell.execute_reply": "2023-11-01T14:05:31.26581Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:31:34.554132700Z",
     "start_time": "2023-11-08T16:31:34.534132200Z"
    }
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_summaries_df, test_prompts_df = preprocess(test_summaries_df, test_prompts_df)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T14:05:31.268655Z",
     "iopub.execute_input": "2023-11-01T14:05:31.268978Z",
     "iopub.status.idle": "2023-11-01T14:05:31.306697Z",
     "shell.execute_reply.started": "2023-11-01T14:05:31.268951Z",
     "shell.execute_reply": "2023-11-01T14:05:31.305134Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:31:34.653171500Z",
     "start_time": "2023-11-08T16:31:34.550132800Z"
    }
   },
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores are being calculated. Please stand by...\n",
      "rouge_1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "527f9b616aa14441ab3cfb084360cd25"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge_2\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04ca40772af14d889f23d7473b6263e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge_l\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fea41bb6ddec49389357ef436ff71062"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge_l_sum\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1072ccd3fa6c4fd097a9f1a050deecb8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "prediction_list = []\n",
    "\n",
    "for index, summary in test_summaries_df.iterrows():\n",
    "\n",
    "        prompt = get_prompt(summary, test_prompts_df)\n",
    "        scores = get_scores(summary)\n",
    "\n",
    "        predictions = model(prompt.prompt_text, summary.text, scores)\n",
    "        content = float(predictions[0])\n",
    "        #wording = float(predictions[1])\n",
    "\n",
    "        prediction_list.append((summary.student_id, content))#, wording))"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T14:11:47.877043Z",
     "iopub.execute_input": "2023-11-01T14:11:47.877464Z",
     "iopub.status.idle": "2023-11-01T14:11:47.894016Z",
     "shell.execute_reply.started": "2023-11-01T14:11:47.877434Z",
     "shell.execute_reply": "2023-11-01T14:11:47.892493Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:31:34.668168900Z",
     "start_time": "2023-11-08T16:31:34.634156300Z"
    }
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "predictions_josef = pd.DataFrame(prediction_list, columns=['student_id', 'content'])"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T14:11:49.544247Z",
     "iopub.execute_input": "2023-11-01T14:11:49.54476Z",
     "iopub.status.idle": "2023-11-01T14:11:49.551864Z",
     "shell.execute_reply.started": "2023-11-01T14:11:49.544726Z",
     "shell.execute_reply": "2023-11-01T14:11:49.550573Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:31:34.701133Z",
     "start_time": "2023-11-08T16:31:34.645131300Z"
    }
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tharrmeehan"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# import stuff"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:31:34.705136200Z",
     "start_time": "2023-11-08T16:31:34.661132200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "#\n",
    "predictions_tharrmeehan = test_summaries_df.copy()\n",
    "predictions_tharrmeehan['wording'] = 0\n",
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:31:34.732132400Z",
     "start_time": "2023-11-08T16:31:34.677137100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Combining"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "     student_id   content\n0  000000ffffff -2.728357\n1  222222cccccc -2.728357\n2  111111eeeeee -2.728357\n3  333333dddddd -2.728357",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>-2.728357</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>222222cccccc</td>\n      <td>-2.728357</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>111111eeeeee</td>\n      <td>-2.728357</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>-2.728357</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_josef.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:31:34.745169500Z",
     "start_time": "2023-11-08T16:31:34.693133800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "     student_id prompt_id            text  rouge1_recall  rouge1_precision  \\\n0  000000ffffff    abc123  Example text 1       0.333333          0.333333   \n1  222222cccccc    abc123  Example text 3       0.333333          0.333333   \n2  111111eeeeee    def789  Example text 2       0.333333          0.333333   \n3  333333dddddd    def789  Example text 4       0.333333          0.333333   \n\n   rouge1_fmeasure  rouge2_recall  rouge2_precision  rouge2_fmeasure  \\\n0         0.333333            0.0               0.0              0.0   \n1         0.333333            0.0               0.0              0.0   \n2         0.333333            0.0               0.0              0.0   \n3         0.333333            0.0               0.0              0.0   \n\n   rougeL_recall  rougeL_precision  rougeL_fmeasure  rougeLsum_recall  \\\n0       0.333333          0.333333         0.333333          0.333333   \n1       0.333333          0.333333         0.333333          0.333333   \n2       0.333333          0.333333         0.333333          0.333333   \n3       0.333333          0.333333         0.333333          0.333333   \n\n   rougeLsum_precision  rougeLsum_fmeasure  wording  \n0             0.333333            0.333333        0  \n1             0.333333            0.333333        0  \n2             0.333333            0.333333        0  \n3             0.333333            0.333333        0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>rouge1_recall</th>\n      <th>rouge1_precision</th>\n      <th>rouge1_fmeasure</th>\n      <th>rouge2_recall</th>\n      <th>rouge2_precision</th>\n      <th>rouge2_fmeasure</th>\n      <th>rougeL_recall</th>\n      <th>rougeL_precision</th>\n      <th>rougeL_fmeasure</th>\n      <th>rougeLsum_recall</th>\n      <th>rougeLsum_precision</th>\n      <th>rougeLsum_fmeasure</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>abc123</td>\n      <td>Example text 1</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>222222cccccc</td>\n      <td>abc123</td>\n      <td>Example text 3</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>111111eeeeee</td>\n      <td>def789</td>\n      <td>Example text 2</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>def789</td>\n      <td>Example text 4</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_tharrmeehan.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:31:34.804160200Z",
     "start_time": "2023-11-08T16:31:34.724133800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "predictions_josef = predictions_josef[['student_id', 'content']]\n",
    "predictions_tharrmeehan = predictions_tharrmeehan[['student_id', 'wording']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:31:34.816134400Z",
     "start_time": "2023-11-08T16:31:34.760137600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "predictions = pd.merge(predictions_josef, predictions_tharrmeehan, on='student_id', how='inner')\n",
    "#predictions = pd.merge(predictions_josef, predictions_tharrmeehan, on='student_id', how='outer')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:31:34.820133500Z",
     "start_time": "2023-11-08T16:31:34.769139100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "predictions.to_csv('submission.csv',index=False)\n",
    "display(pd.read_csv('submission.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-11-01T14:11:50.376936Z",
     "iopub.execute_input": "2023-11-01T14:11:50.377384Z",
     "iopub.status.idle": "2023-11-01T14:11:50.402082Z",
     "shell.execute_reply.started": "2023-11-01T14:11:50.377349Z",
     "shell.execute_reply": "2023-11-01T14:11:50.400444Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T16:31:34.872131900Z",
     "start_time": "2023-11-08T16:31:34.785132500Z"
    }
   },
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "     student_id   content  wording\n0  000000ffffff -2.728357        0\n1  222222cccccc -2.728357        0\n2  111111eeeeee -2.728357        0\n3  333333dddddd -2.728357        0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>-2.728357</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>222222cccccc</td>\n      <td>-2.728357</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>111111eeeeee</td>\n      <td>-2.728357</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>-2.728357</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  }
 ]
}
