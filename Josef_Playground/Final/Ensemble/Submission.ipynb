{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47bac766",
   "metadata": {
    "papermill": {
     "duration": 0.00559,
     "end_time": "2023-12-07T12:26:41.049882",
     "exception": false,
     "start_time": "2023-12-07T12:26:41.044292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Instaling Packages\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "919fe1c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:26:41.063300Z",
     "iopub.status.busy": "2023-12-07T12:26:41.062883Z",
     "iopub.status.idle": "2023-12-07T12:27:04.962331Z",
     "shell.execute_reply": "2023-12-07T12:27:04.961189Z"
    },
    "papermill": {
     "duration": 23.90893,
     "end_time": "2023-12-07T12:27:04.964670",
     "exception": false,
     "start_time": "2023-12-07T12:26:41.055740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install rouge --quiet\n",
    "!pip install textstat --quiet\n",
    "!pip install lightgbm --quiet\n",
    "!pip install optuna --quiet\n",
    "!pip install joblib --quiet\n",
    "!pip install torch --quiet\n",
    "!pip install pandas --quiet\n",
    "!pip install tqdm --quiet\n",
    "!pip install scikit-learn==1.2.2 --quiet\n",
    "!pip install transformers --quiet\n",
    "!pip install nltk --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679e162",
   "metadata": {
    "papermill": {
     "duration": 0.005695,
     "end_time": "2023-12-07T12:27:05.017345",
     "exception": false,
     "start_time": "2023-12-07T12:27:05.011650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Functions\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5db710d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:27:05.029921Z",
     "iopub.status.busy": "2023-12-07T12:27:05.029656Z",
     "iopub.status.idle": "2023-12-07T12:27:05.040111Z",
     "shell.execute_reply": "2023-12-07T12:27:05.039292Z"
    },
    "papermill": {
     "duration": 0.018937,
     "end_time": "2023-12-07T12:27:05.042064",
     "exception": false,
     "start_time": "2023-12-07T12:27:05.023127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_ensemble(ensemble_model, train_df, epochs, criterion, optimizer, verbose=True):\n",
    "    for epoch in tqdm(range(epochs), desc='Training', disable=not verbose):\n",
    "        train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for index, summary in tqdm(train_df.iterrows(), total=len(train_df), leave=False, disable=not verbose):\n",
    "            transformer_preds = torch.Tensor([summary.transformer_content, summary.transformer_wording])\n",
    "            rouge_preds = torch.Tensor([summary.rouge_content, summary.rouge_wording])\n",
    "            lgbm_preds = torch.Tensor([summary.lgbm_content, summary.lgbm_wording])\n",
    "\n",
    "            target = torch.Tensor([summary.content, summary.wording]).to(device)\n",
    "            predictions = ensemble_model(\n",
    "                summary.text,\n",
    "                summary.prompt_title,\n",
    "                summary.prompt_question,\n",
    "                summary.prompt_text,\n",
    "                transformer_preds,\n",
    "                rouge_preds,\n",
    "                lgbm_preds\n",
    "            )\n",
    "\n",
    "            loss = criterion(predictions, target)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            y_true.append([*(float(x) for x in target)])\n",
    "            y_pred.append([*(float(x) for x in predictions)])\n",
    "\n",
    "        if verbose:\n",
    "\n",
    "            rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "            mse = mean_squared_error(y_true, y_pred)\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "            performance = {'RMSE': rmse, 'R2': r2, 'MSE': mse}\n",
    "\n",
    "            print(\"\\nEpoch\", epoch+1)\n",
    "            print(performance)\n",
    "            \n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b78cdf3",
   "metadata": {
    "papermill": {
     "duration": 0.005535,
     "end_time": "2023-12-07T12:27:05.053448",
     "exception": false,
     "start_time": "2023-12-07T12:27:05.047913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b888eb5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:27:05.066042Z",
     "iopub.status.busy": "2023-12-07T12:27:05.065769Z",
     "iopub.status.idle": "2023-12-07T12:27:15.200832Z",
     "shell.execute_reply": "2023-12-07T12:27:15.200077Z"
    },
    "papermill": {
     "duration": 10.14403,
     "end_time": "2023-12-07T12:27:15.203203",
     "exception": false,
     "start_time": "2023-12-07T12:27:05.059173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from ROUGE_Model_Loader import ROUGEModelLoader\n",
    "from Ensemble import EnsembleNN\n",
    "from AIOLightGBM import AIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41762c33",
   "metadata": {
    "papermill": {
     "duration": 0.00588,
     "end_time": "2023-12-07T12:27:15.216407",
     "exception": false,
     "start_time": "2023-12-07T12:27:15.210527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Device Settings\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91d8c227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:27:15.230170Z",
     "iopub.status.busy": "2023-12-07T12:27:15.229528Z",
     "iopub.status.idle": "2023-12-07T12:27:15.294125Z",
     "shell.execute_reply": "2023-12-07T12:27:15.293139Z"
    },
    "papermill": {
     "duration": 0.073752,
     "end_time": "2023-12-07T12:27:15.296289",
     "exception": false,
     "start_time": "2023-12-07T12:27:15.222537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0;34mGPU not available. CPU used.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('\\x1b[0;32mGPU is available.\\x1b[0m')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('\\x1b[0;34mGPU not available. CPU used.\\x1b[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906852ce",
   "metadata": {
    "papermill": {
     "duration": 0.005918,
     "end_time": "2023-12-07T12:27:15.308349",
     "exception": false,
     "start_time": "2023-12-07T12:27:15.302431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading Data\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7388f78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:27:15.321432Z",
     "iopub.status.busy": "2023-12-07T12:27:15.321171Z",
     "iopub.status.idle": "2023-12-07T12:27:15.325174Z",
     "shell.execute_reply": "2023-12-07T12:27:15.324334Z"
    },
    "papermill": {
     "duration": 0.012781,
     "end_time": "2023-12-07T12:27:15.327119",
     "exception": false,
     "start_time": "2023-12-07T12:27:15.314338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = 'data'\n",
    "MODEL_PATH = 'models'\n",
    "TOKENIZER_PATH = 'tokenizers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10711016",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:27:15.340660Z",
     "iopub.status.busy": "2023-12-07T12:27:15.340411Z",
     "iopub.status.idle": "2023-12-07T12:27:15.475344Z",
     "shell.execute_reply": "2023-12-07T12:27:15.474218Z"
    },
    "papermill": {
     "duration": 0.144237,
     "end_time": "2023-12-07T12:27:15.477385",
     "exception": false,
     "start_time": "2023-12-07T12:27:15.333148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data - ok\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Data...\", end=\"\\r\")\n",
    "\n",
    "prompts_test_df = pd.read_csv(f'{DATA_PATH}/prompts_test.csv')\n",
    "prompts_train_df = pd.read_csv(f'{DATA_PATH}/prompts_train.csv')\n",
    "summaries_test_df = pd.read_csv(f'{DATA_PATH}/summaries_test.csv')\n",
    "summaries_train_df = pd.read_csv(f'{DATA_PATH}/summaries_train.csv')\n",
    "\n",
    "merged_test_df = pd.merge(summaries_test_df, prompts_test_df, on='prompt_id')\n",
    "merged_train_df = pd.merge(summaries_train_df, prompts_train_df, on='prompt_id')\n",
    "\n",
    "print(\"Loading Data - ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a00c5e",
   "metadata": {
    "papermill": {
     "duration": 0.006219,
     "end_time": "2023-12-07T12:27:15.490056",
     "exception": false,
     "start_time": "2023-12-07T12:27:15.483837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparing Models\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65b04925",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:27:15.503545Z",
     "iopub.status.busy": "2023-12-07T12:27:15.503230Z",
     "iopub.status.idle": "2023-12-07T12:27:22.199562Z",
     "shell.execute_reply": "2023-12-07T12:27:22.198354Z"
    },
    "papermill": {
     "duration": 6.70532,
     "end_time": "2023-12-07T12:27:22.201564",
     "exception": false,
     "start_time": "2023-12-07T12:27:15.496244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Transformer - ok\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Transformer...\", end=\"\\r\")\n",
    "# Replace the path for the transformer and tokenizer you want to run\n",
    "TRANSFORMER_PATH = f'{MODEL_PATH}/deberta-v3-base/checkpoint-4012'\n",
    "TOKENIZER_PATH = f'{TOKENIZER_PATH}/deberta-v3-base-tokenizer'\n",
    "# Adjust max length to fitted model\n",
    "MAX_LENGTH = 1024\n",
    "\n",
    "transformer = AutoModelForSequenceClassification.from_pretrained(TRANSFORMER_PATH, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "\n",
    "print(\"Loading Transformer - ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29e35e89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:27:22.216445Z",
     "iopub.status.busy": "2023-12-07T12:27:22.215633Z",
     "iopub.status.idle": "2023-12-07T12:27:22.249686Z",
     "shell.execute_reply": "2023-12-07T12:27:22.248828Z"
    },
    "papermill": {
     "duration": 0.043335,
     "end_time": "2023-12-07T12:27:22.251633",
     "exception": false,
     "start_time": "2023-12-07T12:27:22.208298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ROUGE model - ok\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading ROUGE model...\", end=\"\\r\")\n",
    "    \n",
    "target_score = 'both'\n",
    "hidden_dim = 64\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "\n",
    "ROUGE_MODEL_PATH = f'{MODEL_PATH}/rouge_based_models/ROUGE_Based_Model_{target_score}_{hidden_dim}_{epochs}_{lr}.pt'\n",
    "\n",
    "model_loader = ROUGEModelLoader(merged_train_df, hidden_dim, target_score)\n",
    "if os.path.exists(ROUGE_MODEL_PATH):\n",
    "    rouge_model = model_loader.model\n",
    "    rouge_model.load_state_dict(torch.load(ROUGE_MODEL_PATH))\n",
    "else:\n",
    "    print(\"Loading ROUGE model...\")\n",
    "    print(\"Specified ROUGE Based Model doesn't exist. Training it now.\")\n",
    "    model_loader.data_path = '/data/rouge_preprocessed_data.csv'\n",
    "    print(model_loader.train(epochs, lr))\n",
    "    rouge_model = model_loader.model\n",
    "\n",
    "print(\"Loading ROUGE model - ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76160ed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:27:22.265483Z",
     "iopub.status.busy": "2023-12-07T12:27:22.265220Z",
     "iopub.status.idle": "2023-12-07T12:27:22.417058Z",
     "shell.execute_reply": "2023-12-07T12:27:22.415912Z"
    },
    "papermill": {
     "duration": 0.161099,
     "end_time": "2023-12-07T12:27:22.419160",
     "exception": false,
     "start_time": "2023-12-07T12:27:22.258061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LGBM model - ok\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading LGBM model...\", end='\\r')\n",
    "\n",
    "LGBM_MODEL_PATH = f'{MODEL_PATH}/lgbm_models/lgbm_model.joblib'  # Adjust the file type if needed\n",
    "if os.path.exists(LGBM_MODEL_PATH):# and False:\n",
    "    lgbm_model = joblib.load(LGBM_MODEL_PATH)\n",
    "    print(\"Loading LGBM model - ok\")\n",
    "else:\n",
    "    lgbm_model = AIO(merged_train_df, merged_test_df.head())\n",
    "    lgbm_model.run()\n",
    "    # lgbm_model = lgbm.model\n",
    "    print(\"Loading LGBM model - ok\")\n",
    "\n",
    "    # Save the model\n",
    "    print(\"Saving LGBM model...\", end='\\r')\n",
    "    joblib.dump(lgbm_model, f'{MODEL_PATH}/lgbm_models/lgbm_model.joblib')\n",
    "    print(\"Saving LGBM model - ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8005ceb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:27:22.434787Z",
     "iopub.status.busy": "2023-12-07T12:27:22.434110Z",
     "iopub.status.idle": "2023-12-07T12:27:31.881401Z",
     "shell.execute_reply": "2023-12-07T12:27:31.880210Z"
    },
    "papermill": {
     "duration": 9.457158,
     "end_time": "2023-12-07T12:27:31.883585",
     "exception": false,
     "start_time": "2023-12-07T12:27:22.426427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Ensemble model - ok\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing Ensemble model...\", end=\"\\r\")\n",
    "\n",
    "hidden_layers = 1\n",
    "hidden_dim = 64\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "\n",
    "ENSEMBLE_MODEL_PATH = f'{MODEL_PATH}/ensembles/ensemble_{hidden_layers}_{hidden_dim}_{epochs}_{lr}.pt'\n",
    "\n",
    "model = EnsembleNN(\n",
    "        transformer,\n",
    "        tokenizer,\n",
    "        rouge_model,\n",
    "        lgbm_model,\n",
    "        # Adjust max length to fitted model\n",
    "        MAX_LENGTH,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "if os.path.exists(ENSEMBLE_MODEL_PATH):\n",
    "    model.load_state_dict(torch.load(ENSEMBLE_MODEL_PATH, map_location=device))\n",
    "else:\n",
    "    pre_predicted_train_df = model.predict(merged_train_df, ensemble=False)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam\n",
    "    optimizer = optimizer(list(model.parameters()))\n",
    "    optimizer.lr = lr\n",
    "    \n",
    "    y_true, y_pred = train_ensemble(model, pre_predicted_train_df, epochs, criterion, optimizer, verbose=True)\n",
    "    \n",
    "    score_map = {1: 'content', 2: 'wording'}\n",
    "\n",
    "    for i in range(len(y_true[0])):\n",
    "        y_true_i = [y[i] for y in y_true]\n",
    "        y_pred_i = [y[i] for y in y_pred]\n",
    "\n",
    "        rmse = mean_squared_error(y_true_i, y_pred_i, squared=False)\n",
    "        mse = mean_squared_error(y_true_i, y_pred_i)\n",
    "        r2 = r2_score(y_true_i, y_pred_i)\n",
    "\n",
    "        i = score_map[i + 1]\n",
    "        performance = {f'RMSE_{i}': rmse, f'R2_{i}': r2, f'MSE_{i}': mse}\n",
    "\n",
    "        print(performance)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Preparing Ensemble model - ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac440ef9",
   "metadata": {
    "papermill": {
     "duration": 0.006445,
     "end_time": "2023-12-07T12:27:31.897210",
     "exception": false,
     "start_time": "2023-12-07T12:27:31.890765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predicting Test Set\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12a14445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:27:31.911965Z",
     "iopub.status.busy": "2023-12-07T12:27:31.911644Z",
     "iopub.status.idle": "2023-12-07T12:27:34.283187Z",
     "shell.execute_reply": "2023-12-07T12:27:34.282248Z"
    },
    "papermill": {
     "duration": 2.381204,
     "end_time": "2023-12-07T12:27:34.285075",
     "exception": false,
     "start_time": "2023-12-07T12:27:31.903871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transformer:  25%|██▌       | 1/4 [00:00<00:00, 72.36it/s]\n",
      "Transformer:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      "Transformer:  50%|█████     | 2/4 [00:11<00:11,  5.54s/it]\u001B[A\n",
      "Transformer:  75%|███████▌  | 3/4 [00:18<00:06,  6.37s/it]\u001B[A\n",
      "Transformer: 100%|██████████| 4/4 [00:26<00:00,  6.76s/it]\u001B[A\n",
      "ROUGE:  50%|█████     | 2/4 [00:32<00:32, 16.47s/it]      \u001B[A\n",
      "ROUGE:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      "Ensemble:  75%|███████▌  | 3/4 [00:32<00:16, 16.47s/it]\n",
      "Ensemble:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      "100%|██████████| 4/4 [00:33<00:00,  8.25s/it]          \n"
     ]
    }
   ],
   "source": [
    "predicted_test_df = model.predict(merged_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fda8cb89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:27:34.304950Z",
     "iopub.status.busy": "2023-12-07T12:27:34.304676Z",
     "iopub.status.idle": "2023-12-07T12:27:34.325023Z",
     "shell.execute_reply": "2023-12-07T12:27:34.324174Z"
    },
    "papermill": {
     "duration": 0.03238,
     "end_time": "2023-12-07T12:27:34.327007",
     "exception": false,
     "start_time": "2023-12-07T12:27:34.294627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     student_id   content   wording\n0  000000ffffff -1.236509 -1.484966\n1  222222cccccc -1.249943 -1.501786\n2  111111eeeeee -1.244861 -1.495345\n3  333333dddddd -1.251526 -1.504660",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>-1.236509</td>\n      <td>-1.484966</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>222222cccccc</td>\n      <td>-1.249943</td>\n      <td>-1.501786</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>111111eeeeee</td>\n      <td>-1.244861</td>\n      <td>-1.495345</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>-1.251526</td>\n      <td>-1.504660</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission[['student_id', 'content', 'wording']] = predicted_test_df[['student_id', 'ensemble_content', 'ensemble_wording']]\n",
    "submission.to_csv('submission.csv',index=False)\n",
    "display(pd.read_csv('submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43935231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T12:27:34.347093Z",
     "iopub.status.busy": "2023-12-07T12:27:34.346787Z",
     "iopub.status.idle": "2023-12-07T12:27:35.529759Z",
     "shell.execute_reply": "2023-12-07T12:27:35.528975Z"
    },
    "papermill": {
     "duration": 1.195471,
     "end_time": "2023-12-07T12:27:35.532114",
     "exception": false,
     "start_time": "2023-12-07T12:27:34.336643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'/ensemble_{hidden_layers}_{hidden_dim}_{epochs}_{lr}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "323de392",
   "metadata": {
    "papermill": {
     "duration": 0.009213,
     "end_time": "2023-12-07T12:27:35.551111",
     "exception": false,
     "start_time": "2023-12-07T12:27:35.541898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6201832,
     "sourceId": 53482,
     "sourceType": "competition"
    },
    {
     "datasetId": 4119582,
     "sourceId": 7146041,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 60.474435,
   "end_time": "2023-12-07T12:27:38.172805",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-07T12:26:37.698370",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
